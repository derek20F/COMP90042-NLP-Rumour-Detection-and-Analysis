{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_pro1_task1_v4-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae197eee63494d20b124b6a55b7fbb07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d4d48faf382a4bbd9111b9421046e79a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f66228d448224313a4fa554f76749d65",
              "IPY_MODEL_525a876fe0da4064825811f3620549c1"
            ]
          }
        },
        "d4d48faf382a4bbd9111b9421046e79a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f66228d448224313a4fa554f76749d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_edbed7efec114343a5ef930c7b55183a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb8d655aa2dc45c78023f429a01a8952"
          }
        },
        "525a876fe0da4064825811f3620549c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e257ad2822d04b74acc085869d979aea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 11.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_968338e86a554fbeb89f5016ad73ba32"
          }
        },
        "edbed7efec114343a5ef930c7b55183a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb8d655aa2dc45c78023f429a01a8952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e257ad2822d04b74acc085869d979aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "968338e86a554fbeb89f5016ad73ba32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0c3f717b9a648b284a71ed9a155e055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb7ba8b4fa5b40cea52f46bb14a5518b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86529437e7ed42dea13d913ae9c1a3d4",
              "IPY_MODEL_9a954ac711034dffb75e04a7356bb8ef"
            ]
          }
        },
        "fb7ba8b4fa5b40cea52f46bb14a5518b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86529437e7ed42dea13d913ae9c1a3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af0543982c7041788b00eb629297cb4f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5cae8f3fba545719363ef28e758e89c"
          }
        },
        "9a954ac711034dffb75e04a7356bb8ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c6228a714aa4dfe95273093809c229d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:14&lt;00:00, 29.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9534dbdd51da4bb4ba41dc4647a83ec9"
          }
        },
        "af0543982c7041788b00eb629297cb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5cae8f3fba545719363ef28e758e89c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c6228a714aa4dfe95273093809c229d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9534dbdd51da4bb4ba41dc4647a83ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c554e4f50a34166a3aeb5dbfce3dc97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_87391c7f6cf14600a784ea8515b27e95",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c7ea122c5ce4a9cb8ee5bc4ae010d0d",
              "IPY_MODEL_a88188acdbaa4878bb1ff95b3af845e5"
            ]
          }
        },
        "87391c7f6cf14600a784ea8515b27e95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c7ea122c5ce4a9cb8ee5bc4ae010d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_acefe99293b24881b779937fd22caba6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0bfc0581d6f4ef58c9fd47b42f7fc87"
          }
        },
        "a88188acdbaa4878bb1ff95b3af845e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_20bf00d3b21c44a8985bebf9109fec44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 207kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90ca232f37a545b1aa779b6ea9ebe0fc"
          }
        },
        "acefe99293b24881b779937fd22caba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0bfc0581d6f4ef58c9fd47b42f7fc87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20bf00d3b21c44a8985bebf9109fec44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90ca232f37a545b1aa779b6ea9ebe0fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "423746d04f3b4ad98b1a96d14f997bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_511fd817db0c44729b9a8b9408c06620",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_421d35bea4c241dcade58f47d94f9b31",
              "IPY_MODEL_7becf1b5ee064c108eeceeff5697d328"
            ]
          }
        },
        "511fd817db0c44729b9a8b9408c06620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "421d35bea4c241dcade58f47d94f9b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_65f6dd953c924832af0f6af7d91021f8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97ff9b08de714d388c72528ecd4c111c"
          }
        },
        "7becf1b5ee064c108eeceeff5697d328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69f6e533b8f34bda8ec8eae9b86a8e91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 31.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_713768d0999b4cc8a4f894fba0e4ded2"
          }
        },
        "65f6dd953c924832af0f6af7d91021f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97ff9b08de714d388c72528ecd4c111c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69f6e533b8f34bda8ec8eae9b86a8e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "713768d0999b4cc8a4f894fba0e4ded2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50290488e13f45109a1b2d28746ea1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d3788cad077d47778c10ff78ef4625df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_98f6e3ca58554489a5a52ec2a933aca9",
              "IPY_MODEL_67a8cf8f217f493482285afae2f5ba9c"
            ]
          }
        },
        "d3788cad077d47778c10ff78ef4625df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98f6e3ca58554489a5a52ec2a933aca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9006ea50e695466ebb5ab049321d26f5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9dabafe616f4981a4f17480c1ad6e57"
          }
        },
        "67a8cf8f217f493482285afae2f5ba9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15455917fbf94fbabe2497cd33878e1d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.27MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e9d67c3634141738e9721d99b11c785"
          }
        },
        "9006ea50e695466ebb5ab049321d26f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9dabafe616f4981a4f17480c1ad6e57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15455917fbf94fbabe2497cd33878e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e9d67c3634141738e9721d99b11c785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uhaEzig5yge"
      },
      "source": [
        "# Task 1: Rumour Detection System\n",
        "This notebook includes the data pre-processing, BERT language model training, model evaluation, and covid-19 rumour prediction. The code are extracted from the tutorial 6 of COMP90042.\n",
        "This notebook was run on Google Colab with GPU runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHXW4DfJtOwj"
      },
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from IPython.display import display"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UgrQKBV9EVp",
        "outputId": "ceeda4ab-d303-474f-87f9-082c99c4fec4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGQfFPiGtUIv"
      },
      "source": [
        "#%% Read the labels of train data\n",
        "train_label = json.load(open('drive/MyDrive/NLP_Pro1/train.label.json')) #read as a dict\n",
        "dev_label = json.load(open('drive/MyDrive/NLP_Pro1/dev.label.json')) #read as a dict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub2zCf0TtUz_"
      },
      "source": [
        "#%% Read the Tweet Event Data\n",
        "'''\n",
        "The data read is a list of list of dict\n",
        "  A list of Event, \n",
        "  Each Event is a list of Tweets, where the first Tweet in the event is the source, the rest is the reply\n",
        "  Each Tweets is a dict that contain information about that tweet\n",
        "'''\n",
        "train_data = []\n",
        "dev_data = []\n",
        "test_data = []\n",
        "with open('drive/MyDrive/NLP_Pro1/train.data.jsonl') as f:\n",
        "    for line in f:\n",
        "        train_data.append(json.loads(line))\n",
        "with open('drive/MyDrive/NLP_Pro1/dev.data.jsonl') as f:\n",
        "    for line in f:\n",
        "        dev_data.append(json.loads(line))\n",
        "with open('drive/MyDrive/NLP_Pro1/test.data.jsonl') as f:\n",
        "    for line in f:\n",
        "        test_data.append(json.loads(line))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVP6892_tX_G"
      },
      "source": [
        "#%% Pre-process and convert the tweet event data to simple dataframe\n",
        "'''\n",
        "This function take the Twitter Event data and label as input. It will\n",
        "extract and pre-process the text of each tweet, then save the eventID, \n",
        "pre-processed text, and label into a dataframe\n",
        "The pre-processing includes remove \"@mention\" and add [CLS] & [SEP] token for BERT\n",
        "\n",
        "Input:\n",
        "    data: a list of list of dict\n",
        "    label: a dict, if no label available, please input None\n",
        "Output:\n",
        "    a dataframe that contain pre-processed text, eventID, and label\n",
        "'''\n",
        "def dataToDf(data,label):\n",
        "    data_dict = {}\n",
        "    eventTexts = [] #To save the text of all events \n",
        "    eventIds = [] #To save the Id of all events\n",
        "    for event in data:  #every event is a list of list\n",
        "        eventText = '' #To save the text from all tweets of a event\n",
        "        eventId = event[0]['id_str'] #first tweet of an event is the source tweet, take out its ID\n",
        "    \n",
        "        for tweet in event: #first tweet is the source tweet #tweet is a dict\n",
        "            tempText = re.sub(\"@[\\S]*[\\s]?\", \"\", tweet['text']).strip() #remove mention@\n",
        "            #tempText = re.sub(\"#[\\S]*[\\s]?\", \"hashtag\", tempText) #remove hashtag\n",
        "            eventText = eventText +' [SEP] '+tempText.lower()\n",
        "        eventText = eventText + ' [SEP]' #add [SEP] to seperate the text of different tweet in the same event\n",
        "        eventText=eventText.strip()\n",
        "        eventText=eventText.split(' ', 1)[1] #remove the first word '[SEP]'\n",
        "        eventText = '[CLS]'+' '+eventText #attach the [CLS] token before the first tweet (the source tweet)\n",
        "        #print(eventText)\n",
        "        eventTexts.append(eventText)\n",
        "        eventIds.append(eventId)\n",
        "    data_dict['eventID'] = eventIds\n",
        "    data_dict['eventTexts'] = eventTexts\n",
        "    data_dict['label'] = 3 #initialize the label to 3, this value indicated that the label is not provided\n",
        "    tempDf = pd.DataFrame(data = data_dict)\n",
        "    #if the label is provided, then encoded the label\n",
        "    #0==non-rumour, 1==rumour\n",
        "    if label != None:\n",
        "        for key in label.keys():\n",
        "            tempDf.loc[tempDf['eventID']==key,'label'] = label[key]\n",
        "        tempDf['label']=tempDf['label'].apply(lambda x: 1 if x=='rumour' else 0)\n",
        "    return tempDf"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnHHRairtdq3"
      },
      "source": [
        "df_train = dataToDf(train_data,train_label)\n",
        "df_dev = dataToDf(dev_data,dev_label)\n",
        "df_test = dataToDf(test_data,None)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "Ww3jdkcZvj1h",
        "outputId": "c8aef623-e75d-40f2-d42e-d62d6b0a24fe"
      },
      "source": [
        "'''\n",
        "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
        "    display(df_dev)\n",
        "'''    \n",
        "display(df_dev)\n",
        "display(df_test)\n",
        "print(df_dev.loc[4,'eventTexts'])\n",
        "print(len(df_dev.loc[4,'eventTexts']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eventID</th>\n",
              "      <th>eventTexts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>553588913747808256</td>\n",
              "      <td>[CLS] #breaking reports: 2 brothers suspected ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>524949003834634240</td>\n",
              "      <td>[CLS] you are not alone today #ottawa - we are...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>553221281181859841</td>\n",
              "      <td>[CLS] have said it before, but needs saying ag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>580322346508124160</td>\n",
              "      <td>[CLS] germanwings #a320 plane crashes in south...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>544307417677189121</td>\n",
              "      <td>[CLS] hostage situation in sydney\\nto all our ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>525025279803424768</td>\n",
              "      <td>[CLS] the soldier shot dead in wednesday's ott...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>552784600502915072</td>\n",
              "      <td>[CLS] charlie hebdo became well known for publ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>499696525808001024</td>\n",
              "      <td>[CLS] we got through. that's a sniper on top o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>580320612155060224</td>\n",
              "      <td>[CLS] last position of germanwings flight #4u9...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>553218279557582849</td>\n",
              "      <td>[CLS] kudos to google for donating €250,000 to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>580 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                eventID  ... label\n",
              "0    553588913747808256  ...     1\n",
              "1    524949003834634240  ...     0\n",
              "2    553221281181859841  ...     0\n",
              "3    580322346508124160  ...     1\n",
              "4    544307417677189121  ...     1\n",
              "..                  ...  ...   ...\n",
              "575  525025279803424768  ...     1\n",
              "576  552784600502915072  ...     0\n",
              "577  499696525808001024  ...     0\n",
              "578  580320612155060224  ...     1\n",
              "579  553218279557582849  ...     0\n",
              "\n",
              "[580 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eventID</th>\n",
              "      <th>eventTexts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>544382249178001408</td>\n",
              "      <td>[CLS] 5 people have been able to get out of sy...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>525027317551079424</td>\n",
              "      <td>[CLS] new: sources: deceased gunman who killed...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>544273220128739329</td>\n",
              "      <td>[CLS] isis flag visible as gunman seizes sydne...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>499571799764770816</td>\n",
              "      <td>[CLS] people of #ferguson: stop #attacking our...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>552844104418091008</td>\n",
              "      <td>[CLS] #charliehebdo editor, assassinated today...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>553581227165642752</td>\n",
              "      <td>[CLS] we are hearing gunfire at the siege at t...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>552816302780579840</td>\n",
              "      <td>[CLS] “i don’t feel as though i’m killing some...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>580350000074457088</td>\n",
              "      <td>[CLS] we must confirm to our deepest regret th...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>498584409055174656</td>\n",
              "      <td>[CLS] protestors have blocked west florissant,...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>524961070465945600</td>\n",
              "      <td>[CLS] terrible news in ottawa today. thoughts ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>581 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                eventID  ... label\n",
              "0    544382249178001408  ...     3\n",
              "1    525027317551079424  ...     3\n",
              "2    544273220128739329  ...     3\n",
              "3    499571799764770816  ...     3\n",
              "4    552844104418091008  ...     3\n",
              "..                  ...  ...   ...\n",
              "576  553581227165642752  ...     3\n",
              "577  552816302780579840  ...     3\n",
              "578  580350000074457088  ...     3\n",
              "579  498584409055174656  ...     3\n",
              "580  524961070465945600  ...     3\n",
              "\n",
              "[581 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[CLS] hostage situation in sydney\n",
            "to all our fans and friends staying in sydney, stay safe and keep praying... http://t.co/sq62baketz [SEP] people praying is exactly what caused this situation in the first place.\n",
            "#yourgodsnotrealbutmineis [SEP] what if it's an isis attack? so sorry to all those hostages, keep calm because the police will get you out. [SEP] who are you? do i even know you? stay away satan! [SEP]\n",
            "414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiaIADpfSEV_"
      },
      "source": [
        "#df_train = df_train[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkKaTvvowAgv",
        "outputId": "f1c6bbae-04ec-4be3-80e5-60bd62e07a76"
      },
      "source": [
        "!pip install torch torchvision transformers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 20.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 38.2MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206,
          "referenced_widgets": [
            "ae197eee63494d20b124b6a55b7fbb07",
            "d4d48faf382a4bbd9111b9421046e79a",
            "f66228d448224313a4fa554f76749d65",
            "525a876fe0da4064825811f3620549c1",
            "edbed7efec114343a5ef930c7b55183a",
            "eb8d655aa2dc45c78023f429a01a8952",
            "e257ad2822d04b74acc085869d979aea",
            "968338e86a554fbeb89f5016ad73ba32",
            "f0c3f717b9a648b284a71ed9a155e055",
            "fb7ba8b4fa5b40cea52f46bb14a5518b",
            "86529437e7ed42dea13d913ae9c1a3d4",
            "9a954ac711034dffb75e04a7356bb8ef",
            "af0543982c7041788b00eb629297cb4f",
            "b5cae8f3fba545719363ef28e758e89c",
            "9c6228a714aa4dfe95273093809c229d",
            "9534dbdd51da4bb4ba41dc4647a83ec9"
          ]
        },
        "id": "VhoV9jeCzgc8",
        "outputId": "7ff9a6fe-041c-442e-f740-f8289c0294d4"
      },
      "source": [
        "#load pretrained bert base model\n",
        "#this is already trained on a large courpus\n",
        "from transformers import BertModel\n",
        "\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "print(\"Done loading BERT model.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae197eee63494d20b124b6a55b7fbb07",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0c3f717b9a648b284a71ed9a155e055",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done loading BERT model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwUPVoPCzktL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "9c554e4f50a34166a3aeb5dbfce3dc97",
            "87391c7f6cf14600a784ea8515b27e95",
            "9c7ea122c5ce4a9cb8ee5bc4ae010d0d",
            "a88188acdbaa4878bb1ff95b3af845e5",
            "acefe99293b24881b779937fd22caba6",
            "b0bfc0581d6f4ef58c9fd47b42f7fc87",
            "20bf00d3b21c44a8985bebf9109fec44",
            "90ca232f37a545b1aa779b6ea9ebe0fc",
            "423746d04f3b4ad98b1a96d14f997bd2",
            "511fd817db0c44729b9a8b9408c06620",
            "421d35bea4c241dcade58f47d94f9b31",
            "7becf1b5ee064c108eeceeff5697d328",
            "65f6dd953c924832af0f6af7d91021f8",
            "97ff9b08de714d388c72528ecd4c111c",
            "69f6e533b8f34bda8ec8eae9b86a8e91",
            "713768d0999b4cc8a4f894fba0e4ded2",
            "50290488e13f45109a1b2d28746ea1a5",
            "d3788cad077d47778c10ff78ef4625df",
            "98f6e3ca58554489a5a52ec2a933aca9",
            "67a8cf8f217f493482285afae2f5ba9c",
            "9006ea50e695466ebb5ab049321d26f5",
            "c9dabafe616f4981a4f17480c1ad6e57",
            "15455917fbf94fbabe2497cd33878e1d",
            "2e9d67c3634141738e9721d99b11c785"
          ]
        },
        "outputId": "ee318ac1-942b-4dcd-86bb-24b52484349b"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "#load BERT's WordPiece tokenisation model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c554e4f50a34166a3aeb5dbfce3dc97",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "423746d04f3b4ad98b1a96d14f997bd2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50290488e13f45109a1b2d28746ea1a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "qq-mZOIb7Ekb",
        "outputId": "7bbb9236-6a8e-494b-88b7-0a083a797463"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache() #empty the cache before training to prevent memory error\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jCD5JJKrCbM"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "\n",
        "class myDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, maxlen): #dataframe: df_dev or df_train\n",
        "\n",
        "        #Store the contents of the file in a pandas dataframe\n",
        "        self.df = dataframe\n",
        "\n",
        "        #Initialize the BERT tokenizer\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #Selecting the sentence and label at the specified index in the data frame\n",
        "        sentence = self.df.loc[index, 'eventTexts']\n",
        "        label = self.df.loc[index, 'label']\n",
        "        eventID = self.df.loc[index, 'eventID']\n",
        "        #Preprocessing the text to be suitable for BERT\n",
        "        tokens = self.tokenizer.tokenize(sentence) #Tokenize the sentence\n",
        "        \n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
        "\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
        "\n",
        "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label, eventID"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V86sdtCrmt-",
        "outputId": "ce9dffa2-e81f-4c2b-9cb5-8f9fd6b1f9d6"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Creating instances of training and development set\n",
        "#maxlen sets the maximum length a sentence can have\n",
        "#any sentence longer than this length is truncated to the maxlen size\n",
        "train_set = myDataset(filename = df_train, maxlen = 500) \n",
        "dev_set = myDataset(filename = df_dev, maxlen = 500)\n",
        "test_set = myDataset(filename = df_test, maxlen = 500)\n",
        "\n",
        "#Creating intsances of training and development dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size = 10, num_workers = 2) #batch_size = 64\n",
        "dev_loader = DataLoader(dev_set, batch_size = 10, num_workers = 2)\n",
        "\n",
        "print(\"Done preprocessing training and development data.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done preprocessing training and development data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ldCJrNTVz_rq",
        "outputId": "572feb87-f3d8-4956-96cf-a8f29155b332"
      },
      "source": [
        "display(train_loader)\n",
        "display(dev_loader)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f75814adf50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f7581574e10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxj2J5O70zo3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        #Instantiating BERT model object \n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        #Classification layer\n",
        "        #input dimension is 768 because [CLS] embedding has a dimension of 768\n",
        "        #output dimension is 1 because we're working with a binary classification problem\n",
        "        self.cls_layer = nn.Linear(768, 1) #initialize the layer\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "        '''\n",
        "\n",
        "        #Feeding the input to BERT model to obtain contextualized representations\n",
        "        outputs = self.bert_layer(seq, attention_mask = attn_masks)\n",
        "        cont_reps = outputs.last_hidden_state\n",
        "\n",
        "        #Obtaining the representation of [CLS] head (the first token)\n",
        "        cls_rep = cont_reps[:, 0] #for all the context, just take the first cls token\n",
        "\n",
        "        #Feeding cls_rep to the classifier layer\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWWR2MKE1D7S",
        "outputId": "d4c2cf37-592f-47ee-ac12-c7b807227a40"
      },
      "source": [
        "gpu = 0 #gpu ID\n",
        "\n",
        "print(\"Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\")\n",
        "net = SentimentClassifier() #initailize the net\n",
        "net.cuda(gpu) #Enable gpu support for the model #tell the model to move to GPU\n",
        "print(\"Done creating the sentiment classifier.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done creating the sentiment classifier.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U--5rccO4cfB"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()  #BCE: binary cross entropy\n",
        "opti = optim.Adam(net.parameters(), lr = 2e-5) #optimizer"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h6wYc0y4fUy"
      },
      "source": [
        "import time\n",
        "\n",
        "def train(net, criterion, opti, train_loader, dev_loader, max_eps, gpu):\n",
        "    net.train()\n",
        "    best_f1 = 0\n",
        "    st = time.time()\n",
        "    train_loss_curve = []\n",
        "    train_f1_curve = []\n",
        "    dev_loss_curve = []\n",
        "    dev_f1_curve = []\n",
        "    for ep in range(max_eps):\n",
        "        \n",
        "        for it, (seq, attn_masks, labels, eventID) in enumerate(train_loader):\n",
        "            #Clear gradients\n",
        "            opti.zero_grad() #make all the gradient zero  \n",
        "            #Converting these to cuda tensors\n",
        "            #normal tensor is on cpu\n",
        "            #cuda tensor is on gpu\n",
        "            seq, attn_masks, labels = seq.cuda(gpu), attn_masks.cuda(gpu), labels.cuda(gpu)\n",
        "\n",
        "            #Obtaining the logits from the model\n",
        "            logits = net(seq, attn_masks)\n",
        "\n",
        "            #Computing loss\n",
        "            loss = criterion(logits.squeeze(-1), labels.float())\n",
        "\n",
        "            #Backpropagating the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            #Optimization step\n",
        "            opti.step() #update the weight with the gradient\n",
        "              \n",
        "            if it % 30 == 0: #print the train loss and f1 every 30 steps\n",
        "                \n",
        "                f1 = get_accuracy_from_logits(logits, labels, gpu)\n",
        "                print(\"Iteration {} of epoch {} complete. Loss: {}; F1: {}; Time taken (s): {}\".format(it, ep, loss.item(), f1, (time.time()-st)))\n",
        "                train_loss_curve.append(loss.item())\n",
        "                train_f1_curve.append(f1)\n",
        "                st = time.time()\n",
        "\n",
        "        \n",
        "        dev_f1, dev_loss = evaluate(net, criterion, dev_loader, gpu)\n",
        "        dev_loss_curve.append(dev_loss)\n",
        "        dev_f1_curve.append(dev_f1)\n",
        "        print(\"Epoch {} complete! Development F1: {}; Development Loss: {}\".format(ep, dev_f1, dev_loss))\n",
        "        torch.save(net.state_dict(), 'drive/MyDrive/NLP_Pro1/bertcls_{}.dat'.format(ep))\n",
        "        if dev_f1 > best_f1:\n",
        "            print(\"Best development F1 improved from {} to {}, saving model...\".format(best_f1, dev_f1))\n",
        "            best_f1 = dev_f1\n",
        "            torch.save(net.state_dict(), 'drive/MyDrive/NLP_Pro1/bertcls_{}.dat'.format(ep))\n",
        "    print(train_loss_curve)\n",
        "    print(train_f1_curve)\n",
        "    print(dev_loss_curve)\n",
        "    print(dev_f1_curve)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv9kOY-FMu6n"
      },
      "source": [
        "import time\n",
        "\n",
        "def predict(net, data_set, gpu):\n",
        "    data_loader = DataLoader(data_set, batch_size = 1, num_workers = 2)\n",
        "    net.eval() #to fix the model prevent random dropout\n",
        "    predicted_dict = {}\n",
        "    st = time.time() \n",
        "    for it, (seq, attn_masks, labels, eventID) in enumerate(data_loader):\n",
        "        #Clear gradients\n",
        "        with torch.no_grad():\n",
        "        \n",
        "            #Converting these to cuda tensors\n",
        "            #normal tensor is on cpu\n",
        "            #cuda tensor is on gpu\n",
        "            seq, attn_masks, labels = seq.cuda(gpu), attn_masks.cuda(gpu), labels.cuda(gpu)\n",
        "            #print(seq,attn_masks)\n",
        "            #Obtaining the logits from the model\n",
        "            logits = net(seq, attn_masks)\n",
        "            #print(logits)\n",
        "            \n",
        "            probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "            soft_probs = (probs > 0.5).long()\n",
        "            #predictedLabel = int(soft_probs.data[0][0][0])\n",
        "            predictedLabel = int(soft_probs.item())\n",
        "            eventID = eventID[0]\n",
        "            #acc = (soft_probs.squeeze() == labels).float().mean()\n",
        "            if predictedLabel == 1:\n",
        "                predicted_dict[eventID] = \"rumour\"\n",
        "            else: \n",
        "                predicted_dict[eventID] = \"non-rumour\"\n",
        "            '''\n",
        "            print(it)\n",
        "            print(eventID)\n",
        "            print(logits)\n",
        "            print(\"probs={}\".format(probs))\n",
        "            print(\"soft_probs={}\".format(soft_probs))\n",
        "            print(predictedLabel)\n",
        "            print(\" \")\n",
        "            '''\n",
        "    et = time.time()\n",
        "    print(\"time spent on predict is {}\".format(et-st))\n",
        "    return predicted_dict\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QunfXKi64ruz"
      },
      "source": [
        "# This function compute the f1 score\n",
        "def get_accuracy_from_logits(logits, labels, gpu):\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "    soft_probs = (probs > 0.5).long()\n",
        "    batchSize = labels.size()[0]\n",
        "    allTrue = [1] * batchSize\n",
        "    allTrue = torch.FloatTensor(allTrue).cuda(gpu)\n",
        "    precision = (((soft_probs.squeeze() == labels)&(labels==allTrue)).float().mean()) / ((soft_probs.squeeze() == 1).float().mean())\n",
        "    recall = (((soft_probs.squeeze() == labels)&(labels==allTrue)).float().mean()) / (labels==allTrue).float().mean()\n",
        "    f1 = (2*precision*recall) / (precision+recall)\n",
        "    if torch.isnan(f1):\n",
        "        f1 = 0\n",
        "    #print(f1)\n",
        "    return f1\n",
        "\n",
        "def evaluate(net, criterion, dataloader, gpu):\n",
        "    net.eval()\n",
        "\n",
        "    mean_f1, mean_loss = 0, 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for seq, attn_masks, labels, eventID in dataloader:\n",
        "            seq, attn_masks, labels = seq.cuda(gpu), attn_masks.cuda(gpu), labels.cuda(gpu)\n",
        "            logits = net(seq, attn_masks)\n",
        "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
        "            mean_f1 += get_accuracy_from_logits(logits, labels, gpu)\n",
        "            count += 1\n",
        "\n",
        "    return mean_f1 / count, mean_loss / count"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJULoonUXDDo",
        "outputId": "1bfde420-1da7-4948-a8b9-a238d446f9a2"
      },
      "source": [
        "#uncomment this part to load previously trained model.\n",
        "'''\n",
        "net = SentimentClassifier()\n",
        "net.load_state_dict(torch.load('drive/MyDrive/NLP_Pro1/bertcls_19.dat'))\n",
        "net.cuda(gpu) #Enable gpu support for the model #tell the model to move to GPU\n",
        "net.eval()\n",
        "'''"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentClassifier(\n",
              "  (bert_layer): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls_layer): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68BO2JWU4wNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6029b3e-04fd-4aee-ba64-229b02b22b7d"
      },
      "source": [
        "num_epoch = 10\n",
        "\n",
        "#fine-tune the model\n",
        "train(net, criterion, opti, train_loader, dev_loader, num_epoch, gpu)\n",
        "torch.save(net.state_dict(), 'drive/MyDrive/NLP_Pro1/bertcls_{}.dat'.format(num_epoch-1))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 of epoch 0 complete. Loss: 0.0005321679054759443; F1: 1.0; Time taken (s): 1.0595190525054932\n",
            "Iteration 30 of epoch 0 complete. Loss: 0.00017172304796986282; F1: 1.0; Time taken (s): 16.151247262954712\n",
            "Iteration 60 of epoch 0 complete. Loss: 0.00024070090148597956; F1: 1.0; Time taken (s): 16.112316370010376\n",
            "Iteration 90 of epoch 0 complete. Loss: 0.0012424641754478216; F1: 1.0; Time taken (s): 16.117817878723145\n",
            "Iteration 120 of epoch 0 complete. Loss: 0.0031329658813774586; F1: 1.0; Time taken (s): 16.138188362121582\n",
            "Iteration 150 of epoch 0 complete. Loss: 0.0011653919937089086; F1: 1.0; Time taken (s): 16.12478542327881\n",
            "Iteration 180 of epoch 0 complete. Loss: 0.0002350305876461789; F1: 0; Time taken (s): 16.131574869155884\n",
            "Iteration 210 of epoch 0 complete. Loss: 0.00023703357146587223; F1: 1.0; Time taken (s): 16.115753173828125\n",
            "Iteration 240 of epoch 0 complete. Loss: 0.0069624572061002254; F1: 1.0; Time taken (s): 16.12736439704895\n",
            "Iteration 270 of epoch 0 complete. Loss: 0.00014158226258587092; F1: 1.0; Time taken (s): 16.116137981414795\n",
            "Iteration 300 of epoch 0 complete. Loss: 0.0007142761605791748; F1: 1.0; Time taken (s): 16.094073057174683\n",
            "Iteration 330 of epoch 0 complete. Loss: 0.0009472991223447025; F1: 1.0; Time taken (s): 16.108845472335815\n",
            "Iteration 360 of epoch 0 complete. Loss: 0.00014539396215695888; F1: 1.0; Time taken (s): 16.12403631210327\n",
            "Iteration 390 of epoch 0 complete. Loss: 0.00011976068344665691; F1: 1.0; Time taken (s): 16.116751432418823\n",
            "Iteration 420 of epoch 0 complete. Loss: 0.00016686416347511113; F1: 1.0; Time taken (s): 16.13979196548462\n",
            "Iteration 450 of epoch 0 complete. Loss: 0.0002551312791183591; F1: 1.0; Time taken (s): 16.114954710006714\n",
            "Epoch 0 complete! Development F1: 0.7866833806037903; Development Loss: 0.6487764655692696\n",
            "Best development F1 improved from 0 to 0.7866833806037903, saving model...\n",
            "Iteration 0 of epoch 1 complete. Loss: 0.00010736317199189216; F1: 1.0; Time taken (s): 27.529877424240112\n",
            "Iteration 30 of epoch 1 complete. Loss: 7.658882532268763e-05; F1: 1.0; Time taken (s): 15.626842737197876\n",
            "Iteration 60 of epoch 1 complete. Loss: 0.00011381077638361603; F1: 1.0; Time taken (s): 15.631200790405273\n",
            "Iteration 90 of epoch 1 complete. Loss: 0.00035296185524202883; F1: 1.0; Time taken (s): 15.628983974456787\n",
            "Iteration 120 of epoch 1 complete. Loss: 0.000163440709002316; F1: 1.0; Time taken (s): 15.613728284835815\n",
            "Iteration 150 of epoch 1 complete. Loss: 0.00037610330036841333; F1: 1.0; Time taken (s): 15.616339921951294\n",
            "Iteration 180 of epoch 1 complete. Loss: 8.02835202193819e-05; F1: 0; Time taken (s): 15.611519575119019\n",
            "Iteration 210 of epoch 1 complete. Loss: 0.00012744548439513892; F1: 1.0; Time taken (s): 15.619094848632812\n",
            "Iteration 240 of epoch 1 complete. Loss: 0.00041393376886844635; F1: 1.0; Time taken (s): 15.613659381866455\n",
            "Iteration 270 of epoch 1 complete. Loss: 7.513435411965474e-05; F1: 1.0; Time taken (s): 15.621489763259888\n",
            "Iteration 300 of epoch 1 complete. Loss: 8.375204197363928e-05; F1: 1.0; Time taken (s): 15.632000207901001\n",
            "Iteration 330 of epoch 1 complete. Loss: 0.00019146378326695412; F1: 1.0; Time taken (s): 15.595922470092773\n",
            "Iteration 360 of epoch 1 complete. Loss: 9.850668720901012e-05; F1: 1.0; Time taken (s): 15.634784698486328\n",
            "Iteration 390 of epoch 1 complete. Loss: 6.954409036552534e-05; F1: 1.0; Time taken (s): 15.61215877532959\n",
            "Iteration 420 of epoch 1 complete. Loss: 0.00010010291589424014; F1: 1.0; Time taken (s): 15.614379167556763\n",
            "Iteration 450 of epoch 1 complete. Loss: 7.73275169194676e-05; F1: 1.0; Time taken (s): 15.603503227233887\n",
            "Epoch 1 complete! Development F1: 0.7866833806037903; Development Loss: 0.6487764655692696\n",
            "Iteration 0 of epoch 2 complete. Loss: 0.00010736317199189216; F1: 1.0; Time taken (s): 26.25320863723755\n",
            "Iteration 30 of epoch 2 complete. Loss: 7.658882532268763e-05; F1: 1.0; Time taken (s): 15.659743070602417\n",
            "Iteration 60 of epoch 2 complete. Loss: 0.00011381077638361603; F1: 1.0; Time taken (s): 15.617797136306763\n",
            "Iteration 90 of epoch 2 complete. Loss: 0.00035296185524202883; F1: 1.0; Time taken (s): 15.609721899032593\n",
            "Iteration 120 of epoch 2 complete. Loss: 0.000163440709002316; F1: 1.0; Time taken (s): 15.612322330474854\n",
            "Iteration 150 of epoch 2 complete. Loss: 0.00037610330036841333; F1: 1.0; Time taken (s): 15.633085489273071\n",
            "Iteration 180 of epoch 2 complete. Loss: 8.02835202193819e-05; F1: 0; Time taken (s): 15.626471519470215\n",
            "Iteration 210 of epoch 2 complete. Loss: 0.00012744548439513892; F1: 1.0; Time taken (s): 15.62371277809143\n",
            "Iteration 240 of epoch 2 complete. Loss: 0.00041393376886844635; F1: 1.0; Time taken (s): 15.608097791671753\n",
            "Iteration 270 of epoch 2 complete. Loss: 7.513435411965474e-05; F1: 1.0; Time taken (s): 15.629442691802979\n",
            "Iteration 300 of epoch 2 complete. Loss: 8.375204197363928e-05; F1: 1.0; Time taken (s): 15.618962526321411\n",
            "Iteration 330 of epoch 2 complete. Loss: 0.00019146378326695412; F1: 1.0; Time taken (s): 15.625226497650146\n",
            "Iteration 360 of epoch 2 complete. Loss: 9.850668720901012e-05; F1: 1.0; Time taken (s): 15.642740726470947\n",
            "Iteration 390 of epoch 2 complete. Loss: 6.954409036552534e-05; F1: 1.0; Time taken (s): 15.615926027297974\n",
            "Iteration 420 of epoch 2 complete. Loss: 0.00010010291589424014; F1: 1.0; Time taken (s): 15.60243821144104\n",
            "Iteration 450 of epoch 2 complete. Loss: 7.73275169194676e-05; F1: 1.0; Time taken (s): 15.621320009231567\n",
            "Epoch 2 complete! Development F1: 0.7866833806037903; Development Loss: 0.6487764655692696\n",
            "Iteration 0 of epoch 3 complete. Loss: 0.00010736317199189216; F1: 1.0; Time taken (s): 25.51870346069336\n",
            "Iteration 30 of epoch 3 complete. Loss: 7.658882532268763e-05; F1: 1.0; Time taken (s): 15.633899211883545\n",
            "Iteration 60 of epoch 3 complete. Loss: 0.00011381077638361603; F1: 1.0; Time taken (s): 15.597174406051636\n",
            "Iteration 90 of epoch 3 complete. Loss: 0.00035296185524202883; F1: 1.0; Time taken (s): 15.611955404281616\n",
            "Iteration 120 of epoch 3 complete. Loss: 0.000163440709002316; F1: 1.0; Time taken (s): 15.644861936569214\n",
            "Iteration 150 of epoch 3 complete. Loss: 0.00037610330036841333; F1: 1.0; Time taken (s): 15.62987232208252\n",
            "Iteration 180 of epoch 3 complete. Loss: 8.02835202193819e-05; F1: 0; Time taken (s): 15.61397647857666\n",
            "Iteration 210 of epoch 3 complete. Loss: 0.00012744548439513892; F1: 1.0; Time taken (s): 15.615312099456787\n",
            "Iteration 240 of epoch 3 complete. Loss: 0.00041393376886844635; F1: 1.0; Time taken (s): 15.611191034317017\n",
            "Iteration 270 of epoch 3 complete. Loss: 7.513435411965474e-05; F1: 1.0; Time taken (s): 15.629673957824707\n",
            "Iteration 300 of epoch 3 complete. Loss: 8.375204197363928e-05; F1: 1.0; Time taken (s): 15.615793466567993\n",
            "Iteration 330 of epoch 3 complete. Loss: 0.00019146378326695412; F1: 1.0; Time taken (s): 15.607731580734253\n",
            "Iteration 360 of epoch 3 complete. Loss: 9.850668720901012e-05; F1: 1.0; Time taken (s): 15.621813535690308\n",
            "Iteration 390 of epoch 3 complete. Loss: 6.954409036552534e-05; F1: 1.0; Time taken (s): 15.626332521438599\n",
            "Iteration 420 of epoch 3 complete. Loss: 0.00010010291589424014; F1: 1.0; Time taken (s): 15.612918138504028\n",
            "Iteration 450 of epoch 3 complete. Loss: 7.73275169194676e-05; F1: 1.0; Time taken (s): 15.602654457092285\n",
            "Epoch 3 complete! Development F1: 0.7866833806037903; Development Loss: 0.6487764655692696\n",
            "Iteration 0 of epoch 4 complete. Loss: 0.00010736317199189216; F1: 1.0; Time taken (s): 26.331702709197998\n",
            "Iteration 30 of epoch 4 complete. Loss: 7.658882532268763e-05; F1: 1.0; Time taken (s): 15.62515902519226\n",
            "Iteration 60 of epoch 4 complete. Loss: 0.00011381077638361603; F1: 1.0; Time taken (s): 15.662616729736328\n",
            "Iteration 90 of epoch 4 complete. Loss: 0.00035296185524202883; F1: 1.0; Time taken (s): 15.634915590286255\n",
            "Iteration 120 of epoch 4 complete. Loss: 0.000163440709002316; F1: 1.0; Time taken (s): 15.627413988113403\n",
            "Iteration 150 of epoch 4 complete. Loss: 0.00037610330036841333; F1: 1.0; Time taken (s): 15.613651275634766\n",
            "Iteration 180 of epoch 4 complete. Loss: 8.02835202193819e-05; F1: 0; Time taken (s): 15.632169008255005\n",
            "Iteration 210 of epoch 4 complete. Loss: 0.00012744548439513892; F1: 1.0; Time taken (s): 15.611319303512573\n",
            "Iteration 240 of epoch 4 complete. Loss: 0.00041393376886844635; F1: 1.0; Time taken (s): 15.620019912719727\n",
            "Iteration 270 of epoch 4 complete. Loss: 7.513435411965474e-05; F1: 1.0; Time taken (s): 15.62992787361145\n",
            "Iteration 300 of epoch 4 complete. Loss: 8.375204197363928e-05; F1: 1.0; Time taken (s): 15.63103199005127\n",
            "Iteration 330 of epoch 4 complete. Loss: 0.00019146378326695412; F1: 1.0; Time taken (s): 15.633459568023682\n",
            "Iteration 360 of epoch 4 complete. Loss: 9.850668720901012e-05; F1: 1.0; Time taken (s): 15.62827467918396\n",
            "Iteration 390 of epoch 4 complete. Loss: 6.954409036552534e-05; F1: 1.0; Time taken (s): 15.613150358200073\n",
            "Iteration 420 of epoch 4 complete. Loss: 0.00010010291589424014; F1: 1.0; Time taken (s): 15.600665807723999\n",
            "Iteration 450 of epoch 4 complete. Loss: 7.73275169194676e-05; F1: 1.0; Time taken (s): 15.593435049057007\n",
            "Epoch 4 complete! Development F1: 0.7866833806037903; Development Loss: 0.6487764655692696\n",
            "Iteration 0 of epoch 5 complete. Loss: 0.00010736317199189216; F1: 1.0; Time taken (s): 25.119881629943848\n",
            "Iteration 30 of epoch 5 complete. Loss: 7.658882532268763e-05; F1: 1.0; Time taken (s): 15.63997220993042\n",
            "Iteration 60 of epoch 5 complete. Loss: 0.00011381077638361603; F1: 1.0; Time taken (s): 15.626354932785034\n",
            "Iteration 90 of epoch 5 complete. Loss: 0.00035296185524202883; F1: 1.0; Time taken (s): 15.615541458129883\n",
            "Iteration 120 of epoch 5 complete. Loss: 0.000163440709002316; F1: 1.0; Time taken (s): 15.627548694610596\n",
            "Iteration 150 of epoch 5 complete. Loss: 0.00037610330036841333; F1: 1.0; Time taken (s): 15.644089460372925\n",
            "Iteration 180 of epoch 5 complete. Loss: 8.02835202193819e-05; F1: 0; Time taken (s): 15.607721090316772\n",
            "Iteration 210 of epoch 5 complete. Loss: 0.00012744548439513892; F1: 1.0; Time taken (s): 15.60798454284668\n",
            "Iteration 240 of epoch 5 complete. Loss: 0.00041393376886844635; F1: 1.0; Time taken (s): 15.618867874145508\n",
            "Iteration 270 of epoch 5 complete. Loss: 7.513435411965474e-05; F1: 1.0; Time taken (s): 15.613539218902588\n",
            "Iteration 300 of epoch 5 complete. Loss: 8.375204197363928e-05; F1: 1.0; Time taken (s): 15.623561382293701\n",
            "Iteration 330 of epoch 5 complete. Loss: 0.00019146378326695412; F1: 1.0; Time taken (s): 15.64254093170166\n",
            "Iteration 360 of epoch 5 complete. Loss: 9.850668720901012e-05; F1: 1.0; Time taken (s): 15.620872020721436\n",
            "Iteration 390 of epoch 5 complete. Loss: 6.954409036552534e-05; F1: 1.0; Time taken (s): 15.624836206436157\n",
            "Iteration 420 of epoch 5 complete. Loss: 0.00010010291589424014; F1: 1.0; Time taken (s): 15.614745140075684\n",
            "Iteration 450 of epoch 5 complete. Loss: 7.73275169194676e-05; F1: 1.0; Time taken (s): 15.630687475204468\n",
            "Epoch 5 complete! Development F1: 0.7866833806037903; Development Loss: 0.6487764655692696\n",
            "Iteration 0 of epoch 6 complete. Loss: 0.00010736317199189216; F1: 1.0; Time taken (s): 25.18687415122986\n",
            "Iteration 30 of epoch 6 complete. Loss: 7.658882532268763e-05; F1: 1.0; Time taken (s): 15.628966569900513\n",
            "Iteration 60 of epoch 6 complete. Loss: 0.00011381077638361603; F1: 1.0; Time taken (s): 15.62820315361023\n",
            "Iteration 90 of epoch 6 complete. Loss: 0.00035296185524202883; F1: 1.0; Time taken (s): 15.615013122558594\n",
            "Iteration 120 of epoch 6 complete. Loss: 0.000163440709002316; F1: 1.0; Time taken (s): 15.610273599624634\n",
            "Iteration 150 of epoch 6 complete. Loss: 0.00037610330036841333; F1: 1.0; Time taken (s): 15.62770414352417\n",
            "Iteration 180 of epoch 6 complete. Loss: 8.02835202193819e-05; F1: 0; Time taken (s): 15.617362976074219\n",
            "Iteration 210 of epoch 6 complete. Loss: 0.00012744548439513892; F1: 1.0; Time taken (s): 15.61550521850586\n",
            "Iteration 240 of epoch 6 complete. Loss: 0.00041393376886844635; F1: 1.0; Time taken (s): 15.614307880401611\n",
            "Iteration 270 of epoch 6 complete. Loss: 7.513435411965474e-05; F1: 1.0; Time taken (s): 15.621349334716797\n",
            "Iteration 300 of epoch 6 complete. Loss: 8.375204197363928e-05; F1: 1.0; Time taken (s): 15.64042854309082\n",
            "Iteration 330 of epoch 6 complete. Loss: 0.00019146378326695412; F1: 1.0; Time taken (s): 15.6127290725708\n",
            "Iteration 360 of epoch 6 complete. Loss: 9.850668720901012e-05; F1: 1.0; Time taken (s): 15.6163911819458\n",
            "Iteration 390 of epoch 6 complete. Loss: 6.954409036552534e-05; F1: 1.0; Time taken (s): 15.625371932983398\n",
            "Iteration 420 of epoch 6 complete. Loss: 0.00010010291589424014; F1: 1.0; Time taken (s): 15.616722583770752\n",
            "Iteration 450 of epoch 6 complete. Loss: 7.73275169194676e-05; F1: 1.0; Time taken (s): 15.612744808197021\n",
            "Epoch 6 complete! Development F1: 0.7866833806037903; Development Loss: 0.6487764655692696\n",
            "Iteration 0 of epoch 7 complete. Loss: 0.00010736317199189216; F1: 1.0; Time taken (s): 25.631001472473145\n",
            "Iteration 30 of epoch 7 complete. Loss: 7.658882532268763e-05; F1: 1.0; Time taken (s): 15.621178150177002\n",
            "Iteration 60 of epoch 7 complete. Loss: 0.00011381077638361603; F1: 1.0; Time taken (s): 15.624320983886719\n",
            "Iteration 90 of epoch 7 complete. Loss: 0.00035296185524202883; F1: 1.0; Time taken (s): 15.610503673553467\n",
            "Iteration 120 of epoch 7 complete. Loss: 0.000163440709002316; F1: 1.0; Time taken (s): 15.60720181465149\n",
            "Iteration 150 of epoch 7 complete. Loss: 0.00037610330036841333; F1: 1.0; Time taken (s): 15.619948387145996\n",
            "Iteration 180 of epoch 7 complete. Loss: 8.02835202193819e-05; F1: 0; Time taken (s): 15.602598667144775\n",
            "Iteration 210 of epoch 7 complete. Loss: 0.00012744548439513892; F1: 1.0; Time taken (s): 15.622414588928223\n",
            "Iteration 240 of epoch 7 complete. Loss: 0.00041393376886844635; F1: 1.0; Time taken (s): 15.620743989944458\n",
            "Iteration 270 of epoch 7 complete. Loss: 7.513435411965474e-05; F1: 1.0; Time taken (s): 15.625502586364746\n",
            "Iteration 300 of epoch 7 complete. Loss: 8.375204197363928e-05; F1: 1.0; Time taken (s): 15.637529134750366\n",
            "Iteration 330 of epoch 7 complete. Loss: 0.00019146378326695412; F1: 1.0; Time taken (s): 15.61337661743164\n",
            "Iteration 360 of epoch 7 complete. Loss: 9.850668720901012e-05; F1: 1.0; Time taken (s): 15.625781297683716\n",
            "Iteration 390 of epoch 7 complete. Loss: 6.954409036552534e-05; F1: 1.0; Time taken (s): 15.657487392425537\n",
            "Iteration 420 of epoch 7 complete. Loss: 0.00010010291589424014; F1: 1.0; Time taken (s): 15.637683868408203\n",
            "Iteration 450 of epoch 7 complete. Loss: 7.73275169194676e-05; F1: 1.0; Time taken (s): 15.629690885543823\n",
            "Epoch 7 complete! Development F1: 0.7866833806037903; Development Loss: 0.6487764655692696\n",
            "Iteration 0 of epoch 8 complete. Loss: 0.00010736317199189216; F1: 1.0; Time taken (s): 25.043862104415894\n",
            "Iteration 30 of epoch 8 complete. Loss: 7.658882532268763e-05; F1: 1.0; Time taken (s): 15.61836552619934\n",
            "Iteration 60 of epoch 8 complete. Loss: 0.00011381077638361603; F1: 1.0; Time taken (s): 15.62602710723877\n",
            "Iteration 90 of epoch 8 complete. Loss: 0.00035296185524202883; F1: 1.0; Time taken (s): 15.614488363265991\n",
            "Iteration 120 of epoch 8 complete. Loss: 0.000163440709002316; F1: 1.0; Time taken (s): 15.635974168777466\n",
            "Iteration 150 of epoch 8 complete. Loss: 0.00037610330036841333; F1: 1.0; Time taken (s): 15.64206314086914\n",
            "Iteration 180 of epoch 8 complete. Loss: 8.02835202193819e-05; F1: 0; Time taken (s): 15.624683856964111\n",
            "Iteration 210 of epoch 8 complete. Loss: 0.00012744548439513892; F1: 1.0; Time taken (s): 15.617022037506104\n",
            "Iteration 240 of epoch 8 complete. Loss: 0.00041393376886844635; F1: 1.0; Time taken (s): 15.618290662765503\n",
            "Iteration 270 of epoch 8 complete. Loss: 7.513435411965474e-05; F1: 1.0; Time taken (s): 15.62312912940979\n",
            "Iteration 300 of epoch 8 complete. Loss: 8.375204197363928e-05; F1: 1.0; Time taken (s): 15.629942893981934\n",
            "Iteration 330 of epoch 8 complete. Loss: 0.00019146378326695412; F1: 1.0; Time taken (s): 15.602497816085815\n",
            "Iteration 360 of epoch 8 complete. Loss: 9.850668720901012e-05; F1: 1.0; Time taken (s): 15.619978666305542\n",
            "Iteration 390 of epoch 8 complete. Loss: 6.954409036552534e-05; F1: 1.0; Time taken (s): 15.61658763885498\n",
            "Iteration 420 of epoch 8 complete. Loss: 0.00010010291589424014; F1: 1.0; Time taken (s): 15.62442946434021\n",
            "Iteration 450 of epoch 8 complete. Loss: 7.73275169194676e-05; F1: 1.0; Time taken (s): 15.620988845825195\n",
            "Epoch 8 complete! Development F1: 0.7866833806037903; Development Loss: 0.6487764655692696\n",
            "Iteration 0 of epoch 9 complete. Loss: 0.00010736317199189216; F1: 1.0; Time taken (s): 25.202852725982666\n",
            "Iteration 30 of epoch 9 complete. Loss: 7.658882532268763e-05; F1: 1.0; Time taken (s): 15.636384963989258\n",
            "Iteration 60 of epoch 9 complete. Loss: 0.00011381077638361603; F1: 1.0; Time taken (s): 15.620929718017578\n",
            "Iteration 90 of epoch 9 complete. Loss: 0.00035296185524202883; F1: 1.0; Time taken (s): 15.6121985912323\n",
            "Iteration 120 of epoch 9 complete. Loss: 0.000163440709002316; F1: 1.0; Time taken (s): 15.619966506958008\n",
            "Iteration 150 of epoch 9 complete. Loss: 0.00037610330036841333; F1: 1.0; Time taken (s): 15.634246826171875\n",
            "Iteration 180 of epoch 9 complete. Loss: 8.02835202193819e-05; F1: 0; Time taken (s): 15.631434440612793\n",
            "Iteration 210 of epoch 9 complete. Loss: 0.00012744548439513892; F1: 1.0; Time taken (s): 15.633735418319702\n",
            "Iteration 240 of epoch 9 complete. Loss: 0.00041393376886844635; F1: 1.0; Time taken (s): 15.603052377700806\n",
            "Iteration 270 of epoch 9 complete. Loss: 7.513435411965474e-05; F1: 1.0; Time taken (s): 15.609385013580322\n",
            "Iteration 300 of epoch 9 complete. Loss: 8.375204197363928e-05; F1: 1.0; Time taken (s): 15.590410947799683\n",
            "Iteration 330 of epoch 9 complete. Loss: 0.00019146378326695412; F1: 1.0; Time taken (s): 15.61959171295166\n",
            "Iteration 360 of epoch 9 complete. Loss: 9.850668720901012e-05; F1: 1.0; Time taken (s): 15.603551626205444\n",
            "Iteration 390 of epoch 9 complete. Loss: 6.954409036552534e-05; F1: 1.0; Time taken (s): 15.641133069992065\n",
            "Iteration 420 of epoch 9 complete. Loss: 0.00010010291589424014; F1: 1.0; Time taken (s): 15.631549596786499\n",
            "Iteration 450 of epoch 9 complete. Loss: 7.73275169194676e-05; F1: 1.0; Time taken (s): 15.616093397140503\n",
            "Epoch 9 complete! Development F1: 0.7866833806037903; Development Loss: 0.6487764655692696\n",
            "[0.0005321679054759443, 0.00017172304796986282, 0.00024070090148597956, 0.0012424641754478216, 0.0031329658813774586, 0.0011653919937089086, 0.0002350305876461789, 0.00023703357146587223, 0.0069624572061002254, 0.00014158226258587092, 0.0007142761605791748, 0.0009472991223447025, 0.00014539396215695888, 0.00011976068344665691, 0.00016686416347511113, 0.0002551312791183591, 0.00010736317199189216, 7.658882532268763e-05, 0.00011381077638361603, 0.00035296185524202883, 0.000163440709002316, 0.00037610330036841333, 8.02835202193819e-05, 0.00012744548439513892, 0.00041393376886844635, 7.513435411965474e-05, 8.375204197363928e-05, 0.00019146378326695412, 9.850668720901012e-05, 6.954409036552534e-05, 0.00010010291589424014, 7.73275169194676e-05, 0.00010736317199189216, 7.658882532268763e-05, 0.00011381077638361603, 0.00035296185524202883, 0.000163440709002316, 0.00037610330036841333, 8.02835202193819e-05, 0.00012744548439513892, 0.00041393376886844635, 7.513435411965474e-05, 8.375204197363928e-05, 0.00019146378326695412, 9.850668720901012e-05, 6.954409036552534e-05, 0.00010010291589424014, 7.73275169194676e-05, 0.00010736317199189216, 7.658882532268763e-05, 0.00011381077638361603, 0.00035296185524202883, 0.000163440709002316, 0.00037610330036841333, 8.02835202193819e-05, 0.00012744548439513892, 0.00041393376886844635, 7.513435411965474e-05, 8.375204197363928e-05, 0.00019146378326695412, 9.850668720901012e-05, 6.954409036552534e-05, 0.00010010291589424014, 7.73275169194676e-05, 0.00010736317199189216, 7.658882532268763e-05, 0.00011381077638361603, 0.00035296185524202883, 0.000163440709002316, 0.00037610330036841333, 8.02835202193819e-05, 0.00012744548439513892, 0.00041393376886844635, 7.513435411965474e-05, 8.375204197363928e-05, 0.00019146378326695412, 9.850668720901012e-05, 6.954409036552534e-05, 0.00010010291589424014, 7.73275169194676e-05, 0.00010736317199189216, 7.658882532268763e-05, 0.00011381077638361603, 0.00035296185524202883, 0.000163440709002316, 0.00037610330036841333, 8.02835202193819e-05, 0.00012744548439513892, 0.00041393376886844635, 7.513435411965474e-05, 8.375204197363928e-05, 0.00019146378326695412, 9.850668720901012e-05, 6.954409036552534e-05, 0.00010010291589424014, 7.73275169194676e-05, 0.00010736317199189216, 7.658882532268763e-05, 0.00011381077638361603, 0.00035296185524202883, 0.000163440709002316, 0.00037610330036841333, 8.02835202193819e-05, 0.00012744548439513892, 0.00041393376886844635, 7.513435411965474e-05, 8.375204197363928e-05, 0.00019146378326695412, 9.850668720901012e-05, 6.954409036552534e-05, 0.00010010291589424014, 7.73275169194676e-05, 0.00010736317199189216, 7.658882532268763e-05, 0.00011381077638361603, 0.00035296185524202883, 0.000163440709002316, 0.00037610330036841333, 8.02835202193819e-05, 0.00012744548439513892, 0.00041393376886844635, 7.513435411965474e-05, 8.375204197363928e-05, 0.00019146378326695412, 9.850668720901012e-05, 6.954409036552534e-05, 0.00010010291589424014, 7.73275169194676e-05, 0.00010736317199189216, 7.658882532268763e-05, 0.00011381077638361603, 0.00035296185524202883, 0.000163440709002316, 0.00037610330036841333, 8.02835202193819e-05, 0.00012744548439513892, 0.00041393376886844635, 7.513435411965474e-05, 8.375204197363928e-05, 0.00019146378326695412, 9.850668720901012e-05, 6.954409036552534e-05, 0.00010010291589424014, 7.73275169194676e-05, 0.00010736317199189216, 7.658882532268763e-05, 0.00011381077638361603, 0.00035296185524202883, 0.000163440709002316, 0.00037610330036841333, 8.02835202193819e-05, 0.00012744548439513892, 0.00041393376886844635, 7.513435411965474e-05, 8.375204197363928e-05, 0.00019146378326695412, 9.850668720901012e-05, 6.954409036552534e-05, 0.00010010291589424014, 7.73275169194676e-05]\n",
            "[tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), 0, tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), 0, tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), 0, tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), 0, tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), 0, tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), 0, tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), 0, tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), 0, tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), 0, tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), 0, tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0'), tensor(1., device='cuda:0')]\n",
            "[0.6487764655692696, 0.6487764655692696, 0.6487764655692696, 0.6487764655692696, 0.6487764655692696, 0.6487764655692696, 0.6487764655692696, 0.6487764655692696, 0.6487764655692696, 0.6487764655692696]\n",
            "[tensor(0.7867, device='cuda:0'), tensor(0.7867, device='cuda:0'), tensor(0.7867, device='cuda:0'), tensor(0.7867, device='cuda:0'), tensor(0.7867, device='cuda:0'), tensor(0.7867, device='cuda:0'), tensor(0.7867, device='cuda:0'), tensor(0.7867, device='cuda:0'), tensor(0.7867, device='cuda:0'), tensor(0.7867, device='cuda:0')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMQdn1xq5YJz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a002d1aa-4661-4e8c-94b9-8799bca9d57a"
      },
      "source": [
        "params = list(net.parameters())\n",
        "display(len(params))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqVJJLggOiGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e443da1e-49bb-4398-f180-bf31227d4962"
      },
      "source": [
        "test_predicted_dict = predict(net, test_set ,gpu)\n",
        "train_predicted_dict = predict(net, train_set, gpu)\n",
        "dev_predicted_dict = predict(net, dev_set, gpu)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time spent on predict is 19.734493732452393\n",
            "time spent on predict is 125.01564002037048\n",
            "time spent on predict is 15.872421264648438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01XEvIjrHe-i"
      },
      "source": [
        "#display(test_predicted_dict)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKHZbZizmsEn"
      },
      "source": [
        "# Save the predicted labels\n",
        "with open(\"drive/MyDrive/NLP_Pro1/test-output.json\", \"w\") as outfile: \n",
        "    json.dump(test_predicted_dict, outfile,separators=(',', ':'))\n",
        "with open(\"drive/MyDrive/NLP_Pro1/train-output.json\", \"w\") as outfile: \n",
        "    json.dump(train_predicted_dict, outfile,separators=(',', ':'))\n",
        "with open(\"drive/MyDrive/NLP_Pro1/dev-output.json\", \"w\") as outfile: \n",
        "    json.dump(dev_predicted_dict, outfile,separators=(',', ':'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2R38_YjzNPS"
      },
      "source": [
        "Now, we handle the covid data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OuZ4ypwzN0N"
      },
      "source": [
        "#%% Read covid data\n",
        "covid_data = []\n",
        "with open('drive/MyDrive/NLP_Pro1/covid.data.jsonl') as f:\n",
        "    for line in f:\n",
        "        covid_data.append(json.loads(line))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSN6EHRJza0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e463e289-3133-4073-fa3a-36d7f4248683"
      },
      "source": [
        "df_covid = dataToDf(covid_data, None)\n",
        "covid_set = myDataset(filename = df_covid, maxlen = 500)\n",
        "covid_predicted_dict = predict(net, covid_set ,gpu)\n",
        "with open(\"drive/MyDrive/NLP_Pro1/covid-output.json\", \"w\") as outfile: \n",
        "    json.dump(covid_predicted_dict, outfile,separators=(',', ':'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time spent on predict is 565.2573494911194\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}